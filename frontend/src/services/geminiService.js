// src/services/geminiService.js
import { GoogleGenerativeAI } from '@google/generative-ai';

// Initialize Gemini API
const API_KEY = import.meta.env.VITE_GEMINI_API_KEY;

// Debug logs
console.log('üîë API Key present:', !!API_KEY);
console.log('üîë API Key length:', API_KEY?.length || 0);

if (!API_KEY) {
  console.error('‚ùå GEMINI API KEY MISSING!');
}

const genAI = new GoogleGenerativeAI(API_KEY);

// Use the correct model name - gemini-pro (not gemini-1.5-flash)
const model = genAI.getGenerativeModel({ 
  model: 'gemini-2.5-flash'  // This is the stable model name
});

/**
 * Test if Gemini API is working
 */
export async function testGeminiAPI() {
  try {
    console.log('üß™ Testing Gemini API...');
    const result = await model.generateContent('Say "Hello, I am working!" if you can read this.');
    const response = await result.response;
    const text = response.text();
    console.log('‚úÖ API Test Success:', text);
    return { success: true, message: text };
  } catch (error) {
    console.error('‚ùå API Test Failed:', error);
    return { success: false, error: error.message };
  }
}

/**
 * Send a message to Gemini and get a response
 */
export async function sendMessageToGemini(message, conversationHistory = []) {
  try {
    console.log('üì§ Sending to Gemini:', message);
    
    // Build context from conversation history
    const context = conversationHistory
      .slice(-5) // Last 5 messages for context
      .filter(msg => msg.sender && msg.text)
      .map((msg) => `${msg.sender === 'user' ? 'User' : 'Assistant'}: ${msg.text}`)
      .join('\n');

    const prompt = context 
      ? `${context}\nUser: ${message}\nAssistant:` 
      : `User: ${message}\nAssistant:`;

    // Generate response
    const result = await model.generateContent(prompt);
    const response = await result.response;
    const text = response.text();

    console.log('‚úÖ Response received');
    return text;
  } catch (error) {
    console.error('‚ùå Gemini API Error:', error);
    console.error('Error details:', {
      message: error.message,
      status: error.status
    });
    throw new Error(`Failed to get AI response: ${error.message}`);
  }
}

/**
 * Stream responses from Gemini (for real-time typing effect)
 */
export async function streamMessageToGemini(message, onChunk, conversationHistory = []) {
  try {
    console.log('üì§ Streaming to Gemini:', message);
    
    const context = conversationHistory
      .slice(-5)
      .filter(msg => msg.sender && msg.text)
      .map((msg) => `${msg.sender === 'user' ? 'User' : 'Assistant'}: ${msg.text}`)
      .join('\n');

    const prompt = context 
      ? `${context}\nUser: ${message}\nAssistant:` 
      : `User: ${message}\nAssistant:`;

    const result = await model.generateContentStream(prompt);

    let fullText = '';
    for await (const chunk of result.stream) {
      const chunkText = chunk.text();
      fullText += chunkText;
      onChunk(fullText);
    }

    console.log('‚úÖ Streaming completed');
    return fullText;
  } catch (error) {
    console.error('‚ùå Streaming Error:', error);
    throw new Error(`Failed to stream AI response: ${error.message}`);
  }
}